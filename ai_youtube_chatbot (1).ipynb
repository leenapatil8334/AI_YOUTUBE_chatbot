{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cAX287IQQ4BZ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain-community \\\n",
        "               langchain-huggingface \\\n",
        "               faiss-cpu \\\n",
        "               sentence-transformers \\\n",
        "               transformers \\\n",
        "               python-dotenv \\\n",
        "               youtube-transcript-api"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "import gradio as gr\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "import re\n",
        "import os\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "-fqQkev5RIM1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_id(url):\n",
        "    if \"v=\" in url:\n",
        "        return url.split(\"v=\")[1].split(\"&\")[0]\n",
        "    elif \"youtu.be\" in url:\n",
        "        return url.split(\"/\")[-1]\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "UHn5jHGHROC-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_id(url):\n",
        "    match = re.search(r\"(?:v=|\\/)([0-9A-Za-z_-]{11})\", url)\n",
        "    return match.group(1) if match else url.strip()"
      ],
      "metadata": {
        "id": "o8cC5Be-ROAz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "print(dir(YouTubeTranscriptApi))  # should now have get_transcript"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5c5YiHsRN90",
        "outputId": "bed81a7b-782e-42b2-a8aa-9348b8ca763a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'fetch', 'list']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "yt = YouTubeTranscriptApi()\n",
        "available_transcripts = yt.list(\"Ks-_Mh1QhMc\")\n",
        "print(available_transcripts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXMv90OLRN7V",
        "outputId": "70095879-92d1-47a1-f6d4-a44198857982"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For this video (Ks-_Mh1QhMc) transcripts are available in the following languages:\n",
            "\n",
            "(MANUALLY CREATED)\n",
            " - sq (\"Albanian\")[TRANSLATABLE]\n",
            " - ar (\"Arabic\")[TRANSLATABLE]\n",
            " - hy (\"Armenian\")[TRANSLATABLE]\n",
            " - az (\"Azerbaijani\")[TRANSLATABLE]\n",
            " - bg (\"Bulgarian\")[TRANSLATABLE]\n",
            " - my (\"Burmese\")[TRANSLATABLE]\n",
            " - ca (\"Catalan\")[TRANSLATABLE]\n",
            " - zh-CN (\"Chinese (China)\")[TRANSLATABLE]\n",
            " - zh-TW (\"Chinese (Taiwan)\")[TRANSLATABLE]\n",
            " - hr (\"Croatian\")[TRANSLATABLE]\n",
            " - cs (\"Czech\")[TRANSLATABLE]\n",
            " - da (\"Danish\")[TRANSLATABLE]\n",
            " - nl (\"Dutch\")[TRANSLATABLE]\n",
            " - en (\"English\")[TRANSLATABLE]\n",
            " - et (\"Estonian\")[TRANSLATABLE]\n",
            " - fi (\"Finnish\")[TRANSLATABLE]\n",
            " - fr (\"French\")[TRANSLATABLE]\n",
            " - fr-CA (\"French (Canada)\")[TRANSLATABLE]\n",
            " - gl (\"Galician\")[TRANSLATABLE]\n",
            " - ka (\"Georgian\")[TRANSLATABLE]\n",
            " - de (\"German\")[TRANSLATABLE]\n",
            " - el (\"Greek\")[TRANSLATABLE]\n",
            " - iw (\"Hebrew\")[TRANSLATABLE]\n",
            " - hu (\"Hungarian\")[TRANSLATABLE]\n",
            " - id (\"Indonesian\")[TRANSLATABLE]\n",
            " - it (\"Italian\")[TRANSLATABLE]\n",
            " - ja (\"Japanese\")[TRANSLATABLE]\n",
            " - kk (\"Kazakh\")[TRANSLATABLE]\n",
            " - ko (\"Korean\")[TRANSLATABLE]\n",
            " - ku (\"Kurdish\")[TRANSLATABLE]\n",
            " - lv (\"Latvian\")[TRANSLATABLE]\n",
            " - mk (\"Macedonian\")[TRANSLATABLE]\n",
            " - mr (\"Marathi\")[TRANSLATABLE]\n",
            " - mn (\"Mongolian\")[TRANSLATABLE]\n",
            " - no (\"Norwegian\")[TRANSLATABLE]\n",
            " - fa (\"Persian\")[TRANSLATABLE]\n",
            " - pl (\"Polish\")[TRANSLATABLE]\n",
            " - pt (\"Portuguese\")[TRANSLATABLE]\n",
            " - pt-BR (\"Portuguese (Brazil)\")[TRANSLATABLE]\n",
            " - pt-PT (\"Portuguese (Portugal)\")[TRANSLATABLE]\n",
            " - ro (\"Romanian\")[TRANSLATABLE]\n",
            " - ru (\"Russian\")[TRANSLATABLE]\n",
            " - sr (\"Serbian\")[TRANSLATABLE]\n",
            " - sk (\"Slovak\")[TRANSLATABLE]\n",
            " - sl (\"Slovenian\")[TRANSLATABLE]\n",
            " - es (\"Spanish\")[TRANSLATABLE]\n",
            " - sv (\"Swedish\")[TRANSLATABLE]\n",
            " - ta (\"Tamil\")[TRANSLATABLE]\n",
            " - th (\"Thai\")[TRANSLATABLE]\n",
            " - tr (\"Turkish\")[TRANSLATABLE]\n",
            " - uk (\"Ukrainian\")[TRANSLATABLE]\n",
            " - vi (\"Vietnamese\")[TRANSLATABLE]\n",
            "\n",
            "(GENERATED)\n",
            " - en (\"English (auto-generated)\")[TRANSLATABLE]\n",
            "\n",
            "(TRANSLATION LANGUAGES)\n",
            " - ar (\"Arabic\")\n",
            " - zh-Hant (\"Chinese (Traditional)\")\n",
            " - nl (\"Dutch\")\n",
            " - en (\"English\")\n",
            " - fr (\"French\")\n",
            " - de (\"German\")\n",
            " - hi (\"Hindi\")\n",
            " - id (\"Indonesian\")\n",
            " - it (\"Italian\")\n",
            " - ja (\"Japanese\")\n",
            " - ko (\"Korean\")\n",
            " - pt (\"Portuguese\")\n",
            " - ru (\"Russian\")\n",
            " - es (\"Spanish\")\n",
            " - th (\"Thai\")\n",
            " - tr (\"Turkish\")\n",
            " - uk (\"Ukrainian\")\n",
            " - vi (\"Vietnamese\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_dicts = [\n",
        "    {\"start\": e.start, \"duration\": e.duration, \"text\": e.text}\n",
        "    for e in yt.fetch(\"Ks-_Mh1QhMc\", languages=['en'])\n",
        "]\n",
        "print(transcript_dicts[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhh596mtRN4M",
        "outputId": "4eafc16f-842e-4150-94df-bd5609fc0130"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'start': 0.0, 'duration': 7.0, 'text': 'Translator: Joseph Geni\\nReviewer: Morton Bast'}, {'start': 15.967, 'duration': 5.398, 'text': 'So I want to start by offering you\\na free no-tech life hack,'}, {'start': 21.389, 'duration': 2.597, 'text': 'and all it requires of you is this:'}, {'start': 24.01, 'duration': 4.163, 'text': 'that you change your posture\\nfor two minutes.'}, {'start': 28.197, 'duration': 3.4, 'text': 'But before I give it away,\\nI want to ask you to right now'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "yt = YouTubeTranscriptApi()\n",
        "\n",
        "def get_transcript_dict(video_id, lang='en'):\n",
        "    return [\n",
        "        {\"start\": e.start, \"duration\": e.duration, \"text\": e.text}\n",
        "        for e in yt.fetch(video_id, languages=[lang])\n",
        "    ]\n",
        "\n",
        "# Example:\n",
        "transcript = get_transcript_dict(\"Ks-_Mh1QhMc\")"
      ],
      "metadata": {
        "id": "BMC4KOFzRN1m"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Join transcript entries into one big string\n",
        "full_text = \" \".join(entry[\"text\"] for entry in transcript)\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "chunks = splitter.create_documents([full_text])\n",
        "\n",
        "print(chunks[0].page_content)  # Check first chunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH7ir9g6RNyz",
        "outputId": "8f1ffa42-3931-4d1f-8e31-4e28fb8e29dd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translator: Joseph Geni\n",
            "Reviewer: Morton Bast So I want to start by offering you\n",
            "a free no-tech life hack, and all it requires of you is this: that you change your posture\n",
            "for two minutes. But before I give it away,\n",
            "I want to ask you to right now do a little audit of your body\n",
            "and what you're doing with your body. So how many of you are\n",
            "sort of making yourselves smaller? Maybe you're hunching, crossing your legs,\n",
            "maybe wrapping your ankles. Sometimes we hold onto our arms like this. Sometimes we spread out. (Laughter) I see you. So I want you to pay attention\n",
            "to what you're doing right now. We're going to come back\n",
            "to that in a few minutes, and I'm hoping that if you learn\n",
            "to tweak this a little bit, it could significantly change\n",
            "the way your life unfolds. So, we're really fascinated\n",
            "with body language, and we're particularly interested\n",
            "in other people's body language. You know, we're interested in,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAETd4OfRNwJ",
        "outputId": "38fcdf6f-b462-40d0-d13b-ea3d3ea9500b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1c & 1d - Indexing (Embedding Generation and Storing in Vector Store)\n",
        "\n"
      ],
      "metadata": {
        "id": "QXFRuu03SMZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "n7uHaDHNRNtT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "Bdw8lRecSRE8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.index_to_docstore_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yih3Yym8SUs_",
        "outputId": "8a2f8831-7fa2-465e-a5df-0194ce83ef5d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'acfbdc00-47ed-4f97-9036-3a862d0cf753',\n",
              " 1: 'd3d94231-1274-4f74-8fe8-82a3e7b36af4',\n",
              " 2: '372a2ea1-164b-4241-84d1-883f93f46486',\n",
              " 3: 'a0a310a2-9823-4fee-a16c-e46c25471606',\n",
              " 4: '793cb13b-8e35-4c7f-b094-8c66e3e62eba',\n",
              " 5: '0876d7cf-5e31-45db-bbb5-a13486ebd8f0',\n",
              " 6: '83495bc5-bad5-44c9-a6a9-818e8f507261',\n",
              " 7: 'bcde53f9-3416-427f-96da-ae89bcc17f8b',\n",
              " 8: 'c9bd7f90-f948-4851-98e6-1c09980f9a93',\n",
              " 9: 'fbce1c5d-4364-4773-b4b2-00ded8d446ad',\n",
              " 10: '05b020dd-1c03-45f4-91b2-da6e9c9bd204',\n",
              " 11: '57a6fb79-6bf7-4455-a3a0-5ce55c58e94d',\n",
              " 12: '09b8d0e5-9694-483b-8f14-6cdf8efe0394',\n",
              " 13: '060d209b-9a6f-4499-98d3-38139c51b905',\n",
              " 14: 'b5f59a6f-2eef-4150-b134-457ff001e4a3',\n",
              " 15: '9090ac08-7126-400e-b54d-9e84714991e4',\n",
              " 16: '18f04c87-8eb6-45c1-8895-8e7099f1258e',\n",
              " 17: '8c8bb16b-3aa8-459d-9fa6-27501f319d74',\n",
              " 18: 'e001cef1-6182-4ea2-85f6-c197e263a0f6',\n",
              " 19: 'f9af39f8-4eea-4dae-b333-6cee913b30c8',\n",
              " 20: 'c467ea4c-a5fd-4f62-a556-0f9ed709fcd9',\n",
              " 21: 'e8fb10b5-6c80-454c-8099-d84a553eb87f',\n",
              " 22: '19a48965-f5f2-4117-a798-c424c2276935',\n",
              " 23: '6c4c78b4-c129-4a6c-b89f-04b595ea6299'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.get_by_ids(['c0cc193e-bfc2-4329-9d33-fd2d4d46a131'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErLjrNz2SUpm",
        "outputId": "1fe6cd3b-dce6-461f-a725-c6bef4caac17"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cached_vector_store = {}\n"
      ],
      "metadata": {
        "id": "A6CnrdzBSUme"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector_store(video_id, chunks, embeddings):\n",
        "    if video_id not in cached_vector_store:\n",
        "        cached_vector_store[video_id] = FAISS.from_documents(chunks, embeddings)\n",
        "    return cached_vector_store[video_id]"
      ],
      "metadata": {
        "id": "bMYvkv4xSUjX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = get_vector_store(\"Ks-_Mh1QhMc\", chunks, embeddings)\n"
      ],
      "metadata": {
        "id": "GdrMQGLCSUgQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - Retrieval\n"
      ],
      "metadata": {
        "id": "cUfS8IIDSpXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
      ],
      "metadata": {
        "id": "31ahHUyuSUdn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4mvnqwOSUaw",
        "outputId": "aad1945d-804b-4c43-cf3c-37224f54b65f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7e1e57387bd0>, search_kwargs={'k': 4})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3 - Augmentation"
      ],
      "metadata": {
        "id": "MR2pmb0xS2I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
        "\n",
        "# Use a model that works well via Hugging Face Inference API\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",  # or any from the table\n",
        "    task=\"text-generation\"\n",
        ")\n",
        "\n",
        "# Wrap for chat-style usage\n",
        "model = ChatHuggingFace(llm=llm)"
      ],
      "metadata": {
        "id": "R3vJVtN4SUX6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"\n",
        "You are an expert assistant that answers questions based on a YouTube transcript.\n",
        "\n",
        "Here is the transcript chunk:\\n\\n{context}\n",
        "\n",
        "Answer the following question as clearly and specifically as possible:\n",
        "{question}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "bNVd3TKCS-QF"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question          = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
        "retrieved_docs    = retriever.invoke(question)"
      ],
      "metadata": {
        "id": "cTtAov0pS-M8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfqVDWfzS-KG",
        "outputId": "68273f42-e387-4ecb-a5c1-320923f9452e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='9f35d186-a70e-42ab-91a9-e0291a775c9e', metadata={}, page_content='that individual\\'s testosterone has gone up significantly and his cortisol\\nhas dropped significantly. So we have this evidence,\\nboth that the body can shape the mind, at least at the facial level, and also that role changes\\ncan shape the mind. So what happens, okay,\\nyou take a role change, what happens if you do that\\nat a really minimal level, like this tiny manipulation,\\nthis tiny intervention? \"For two minutes,\" you say,\\n\"I want you to stand like this, and it\\'s going to make you feel\\nmore powerful.\" So this is what we did. We decided to bring people into the lab\\nand run a little experiment, and these people adopted, for two minutes, either high-power poses\\nor low-power poses, and I\\'m just going to show\\nyou five of the poses, although they took on only two. So here\\'s one. A couple more. This one has been dubbed\\nthe \"Wonder Woman\" by the media. Here are a couple more. So you can be standing\\nor you can be sitting. And here are the low-power poses. So you\\'re folding up,'),\n",
              " Document(id='dabdf505-0b82-4674-b34c-1b264f9874cf', metadata={}, page_content='or low-power poses again, they go through\\na very stressful job interview. It\\'s five minutes long.\\nThey are being recorded. They\\'re being judged also, and the judges are trained\\nto give no nonverbal feedback, so they look like this. Imagine this is the person\\ninterviewing you. So for five minutes, nothing,\\nand this is worse than being heckled. People hate this. It\\'s what Marianne LaFrance calls\\n\"standing in social quicksand.\" So this really spikes your cortisol. So this is the job interview\\nwe put them through, because we really wanted\\nto see what happened. We then have these coders look\\nat these tapes, four of them. They\\'re blind to the hypothesis.\\nThey\\'re blind to the conditions. They have no idea\\nwho\\'s been posing in what pose, and they end up looking\\nat these sets of tapes, and they say,\\n\"We want to hire these people,\" all the high-power posers. \"We don\\'t want to hire these people. We also evaluate these people'),\n",
              " Document(id='c3df83c2-deea-418e-a326-161425994ba0', metadata={}, page_content=\"in the classroom, and what do I notice? I notice that MBA students really exhibit\\nthe full range of power nonverbals. So you have people\\nwho are like caricatures of alphas, really coming into the room, they get\\nright into the middle of the room before class even starts,\\nlike they really want to occupy space. When they sit down,\\nthey're sort of spread out. They raise their hands like this. You have other people\\nwho are virtually collapsing when they come in.\\nAs soon they come in, you see it. You see it on their faces\\nand their bodies, and they sit in their chair\\nand they make themselves tiny, and they go like this\\nwhen they raise their hand. I notice a couple of things about this. One, you're not going to be surprised. It seems to be related to gender. So women are much more likely\\nto do this kind of thing than men. Women feel chronically\\nless powerful than men, so this is not surprising. But the other thing I noticed is that it also seemed\"),\n",
              " Document(id='4bdcc684-6ec5-4c29-8b08-da25e4428d58', metadata={}, page_content=\"less powerful than men, so this is not surprising. But the other thing I noticed is that it also seemed\\nto be related to the extent to which the students were participating,\\nand how well they were participating. And this is really important\\nin the MBA classroom, because participation\\ncounts for half the grade. So business schools have been struggling\\nwith this gender grade gap. You get these equally qualified\\nwomen and men coming in and then you get\\nthese differences in grades, and it seems to be partly\\nattributable to participation. So I started to wonder, you know, okay, so you have these people coming in\\nlike this, and they're participating. Is it possible that we could\\nget people to fake it and would it lead them\\nto participate more? So my main collaborator\\nDana Carney, who's at Berkeley, and I really wanted to know,\\ncan you fake it till you make it? Like, can you do this\\njust for a little while and actually experience\")]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "context_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "DU1121FPS-HP",
        "outputId": "eeea9b6b-4a08-40f7-868c-3b8ed15469f6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'that individual\\'s testosterone has gone up significantly and his cortisol\\nhas dropped significantly. So we have this evidence,\\nboth that the body can shape the mind, at least at the facial level, and also that role changes\\ncan shape the mind. So what happens, okay,\\nyou take a role change, what happens if you do that\\nat a really minimal level, like this tiny manipulation,\\nthis tiny intervention? \"For two minutes,\" you say,\\n\"I want you to stand like this, and it\\'s going to make you feel\\nmore powerful.\" So this is what we did. We decided to bring people into the lab\\nand run a little experiment, and these people adopted, for two minutes, either high-power poses\\nor low-power poses, and I\\'m just going to show\\nyou five of the poses, although they took on only two. So here\\'s one. A couple more. This one has been dubbed\\nthe \"Wonder Woman\" by the media. Here are a couple more. So you can be standing\\nor you can be sitting. And here are the low-power poses. So you\\'re folding up,\\n\\nor low-power poses again, they go through\\na very stressful job interview. It\\'s five minutes long.\\nThey are being recorded. They\\'re being judged also, and the judges are trained\\nto give no nonverbal feedback, so they look like this. Imagine this is the person\\ninterviewing you. So for five minutes, nothing,\\nand this is worse than being heckled. People hate this. It\\'s what Marianne LaFrance calls\\n\"standing in social quicksand.\" So this really spikes your cortisol. So this is the job interview\\nwe put them through, because we really wanted\\nto see what happened. We then have these coders look\\nat these tapes, four of them. They\\'re blind to the hypothesis.\\nThey\\'re blind to the conditions. They have no idea\\nwho\\'s been posing in what pose, and they end up looking\\nat these sets of tapes, and they say,\\n\"We want to hire these people,\" all the high-power posers. \"We don\\'t want to hire these people. We also evaluate these people\\n\\nin the classroom, and what do I notice? I notice that MBA students really exhibit\\nthe full range of power nonverbals. So you have people\\nwho are like caricatures of alphas, really coming into the room, they get\\nright into the middle of the room before class even starts,\\nlike they really want to occupy space. When they sit down,\\nthey\\'re sort of spread out. They raise their hands like this. You have other people\\nwho are virtually collapsing when they come in.\\nAs soon they come in, you see it. You see it on their faces\\nand their bodies, and they sit in their chair\\nand they make themselves tiny, and they go like this\\nwhen they raise their hand. I notice a couple of things about this. One, you\\'re not going to be surprised. It seems to be related to gender. So women are much more likely\\nto do this kind of thing than men. Women feel chronically\\nless powerful than men, so this is not surprising. But the other thing I noticed is that it also seemed\\n\\nless powerful than men, so this is not surprising. But the other thing I noticed is that it also seemed\\nto be related to the extent to which the students were participating,\\nand how well they were participating. And this is really important\\nin the MBA classroom, because participation\\ncounts for half the grade. So business schools have been struggling\\nwith this gender grade gap. You get these equally qualified\\nwomen and men coming in and then you get\\nthese differences in grades, and it seems to be partly\\nattributable to participation. So I started to wonder, you know, okay, so you have these people coming in\\nlike this, and they\\'re participating. Is it possible that we could\\nget people to fake it and would it lead them\\nto participate more? So my main collaborator\\nDana Carney, who\\'s at Berkeley, and I really wanted to know,\\ncan you fake it till you make it? Like, can you do this\\njust for a little while and actually experience'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})"
      ],
      "metadata": {
        "id": "oDJRwn0ES-EH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEWBng6pS-BA",
        "outputId": "0775b767-36e0-4bae-a2a9-657bdc986d99"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='\\nYou are an expert assistant that answers questions based on a YouTube transcript.\\n\\nHere is the transcript chunk:\\n\\nthat individual\\'s testosterone has gone up significantly and his cortisol\\nhas dropped significantly. So we have this evidence,\\nboth that the body can shape the mind, at least at the facial level, and also that role changes\\ncan shape the mind. So what happens, okay,\\nyou take a role change, what happens if you do that\\nat a really minimal level, like this tiny manipulation,\\nthis tiny intervention? \"For two minutes,\" you say,\\n\"I want you to stand like this, and it\\'s going to make you feel\\nmore powerful.\" So this is what we did. We decided to bring people into the lab\\nand run a little experiment, and these people adopted, for two minutes, either high-power poses\\nor low-power poses, and I\\'m just going to show\\nyou five of the poses, although they took on only two. So here\\'s one. A couple more. This one has been dubbed\\nthe \"Wonder Woman\" by the media. Here are a couple more. So you can be standing\\nor you can be sitting. And here are the low-power poses. So you\\'re folding up,\\n\\nor low-power poses again, they go through\\na very stressful job interview. It\\'s five minutes long.\\nThey are being recorded. They\\'re being judged also, and the judges are trained\\nto give no nonverbal feedback, so they look like this. Imagine this is the person\\ninterviewing you. So for five minutes, nothing,\\nand this is worse than being heckled. People hate this. It\\'s what Marianne LaFrance calls\\n\"standing in social quicksand.\" So this really spikes your cortisol. So this is the job interview\\nwe put them through, because we really wanted\\nto see what happened. We then have these coders look\\nat these tapes, four of them. They\\'re blind to the hypothesis.\\nThey\\'re blind to the conditions. They have no idea\\nwho\\'s been posing in what pose, and they end up looking\\nat these sets of tapes, and they say,\\n\"We want to hire these people,\" all the high-power posers. \"We don\\'t want to hire these people. We also evaluate these people\\n\\nin the classroom, and what do I notice? I notice that MBA students really exhibit\\nthe full range of power nonverbals. So you have people\\nwho are like caricatures of alphas, really coming into the room, they get\\nright into the middle of the room before class even starts,\\nlike they really want to occupy space. When they sit down,\\nthey\\'re sort of spread out. They raise their hands like this. You have other people\\nwho are virtually collapsing when they come in.\\nAs soon they come in, you see it. You see it on their faces\\nand their bodies, and they sit in their chair\\nand they make themselves tiny, and they go like this\\nwhen they raise their hand. I notice a couple of things about this. One, you\\'re not going to be surprised. It seems to be related to gender. So women are much more likely\\nto do this kind of thing than men. Women feel chronically\\nless powerful than men, so this is not surprising. But the other thing I noticed is that it also seemed\\n\\nless powerful than men, so this is not surprising. But the other thing I noticed is that it also seemed\\nto be related to the extent to which the students were participating,\\nand how well they were participating. And this is really important\\nin the MBA classroom, because participation\\ncounts for half the grade. So business schools have been struggling\\nwith this gender grade gap. You get these equally qualified\\nwomen and men coming in and then you get\\nthese differences in grades, and it seems to be partly\\nattributable to participation. So I started to wonder, you know, okay, so you have these people coming in\\nlike this, and they\\'re participating. Is it possible that we could\\nget people to fake it and would it lead them\\nto participate more? So my main collaborator\\nDana Carney, who\\'s at Berkeley, and I really wanted to know,\\ncan you fake it till you make it? Like, can you do this\\njust for a little while and actually experience\\n\\nAnswer the following question as clearly and specifically as possible:\\nis the topic of nuclear fusion discussed in this video? if yes then what was discussed\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4 - Generation"
      ],
      "metadata": {
        "id": "KK0shsVQTPyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "answer = model.invoke(final_prompt)\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoGBbMY3S9-a",
        "outputId": "0be0b23a-6337-4bf7-bf0a-73709af98f5a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No, the topic of nuclear fusion is not discussed in this video. The transcript appears to be from a lecture or presentation about social psychology, specifically the topic of power dynamics and nonverbal behavior. The discussion centers around the concept of \"power posing,\" the idea that adopting certain body postures can affect a person's feelings of power and confidence, and how this concept relates to participation and performance in a business school classroom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "WsOdE2hDS96w"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(retrieved_docs):\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  return context_text"
      ],
      "metadata": {
        "id": "4Bfi7QO6S94I"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain = RunnableParallel({\n",
        "    'context': retriever | RunnableLambda(format_docs),\n",
        "    'question': RunnablePassthrough()\n",
        "})"
      ],
      "metadata": {
        "id": "G4ziFdF5S91C"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parallel_chain.invoke('who is Demis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxcZdu57S9xy",
        "outputId": "627948ee-bf1d-4d98-d2ee-0ff1c8379398"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'Translator: Joseph Geni\\nReviewer: Morton Bast So I want to start by offering you\\na free no-tech life hack, and all it requires of you is this: that you change your posture\\nfor two minutes. But before I give it away,\\nI want to ask you to right now do a little audit of your body\\nand what you\\'re doing with your body. So how many of you are\\nsort of making yourselves smaller? Maybe you\\'re hunching, crossing your legs,\\nmaybe wrapping your ankles. Sometimes we hold onto our arms like this. Sometimes we spread out. (Laughter) I see you. So I want you to pay attention\\nto what you\\'re doing right now. We\\'re going to come back\\nto that in a few minutes, and I\\'m hoping that if you learn\\nto tweak this a little bit, it could significantly change\\nthe way your life unfolds. So, we\\'re really fascinated\\nwith body language, and we\\'re particularly interested\\nin other people\\'s body language. You know, we\\'re interested in,\\n\\nbut for a long time I had been thinking, \"Not supposed to be here.\" So at the end of my first year at Harvard, a student who had not talked\\nin class the entire semester, who I had said, \"Look, you\\'ve gotta\\nparticipate or else you\\'re going to fail,\" came into my office.\\nI really didn\\'t know her at all. She came in totally defeated,\\nand she said, \"I\\'m not supposed to be here.\" And that was the moment for me. Because two things happened. One was that I realized, oh my gosh,\\nI don\\'t feel like that anymore. I don\\'t feel that anymore,\\nbut she does, and I get that feeling. And the second was,\\nshe is supposed to be here! Like, she can fake it, she can become it. So I was like, \"Yes, you are!\\nYou are supposed to be here! And tomorrow you\\'re going to fake it, you\\'re going to make yourself\\npowerful, and, you know -- (Applause) And you\\'re going to go\\ninto the classroom, and you are going to give\\nthe best comment ever.\" You know? And she gave\\n\\nthat individual\\'s testosterone has gone up significantly and his cortisol\\nhas dropped significantly. So we have this evidence,\\nboth that the body can shape the mind, at least at the facial level, and also that role changes\\ncan shape the mind. So what happens, okay,\\nyou take a role change, what happens if you do that\\nat a really minimal level, like this tiny manipulation,\\nthis tiny intervention? \"For two minutes,\" you say,\\n\"I want you to stand like this, and it\\'s going to make you feel\\nmore powerful.\" So this is what we did. We decided to bring people into the lab\\nand run a little experiment, and these people adopted, for two minutes, either high-power poses\\nor low-power poses, and I\\'m just going to show\\nyou five of the poses, although they took on only two. So here\\'s one. A couple more. This one has been dubbed\\nthe \"Wonder Woman\" by the media. Here are a couple more. So you can be standing\\nor you can be sitting. And here are the low-power poses. So you\\'re folding up,\\n\\nor low-power poses again, they go through\\na very stressful job interview. It\\'s five minutes long.\\nThey are being recorded. They\\'re being judged also, and the judges are trained\\nto give no nonverbal feedback, so they look like this. Imagine this is the person\\ninterviewing you. So for five minutes, nothing,\\nand this is worse than being heckled. People hate this. It\\'s what Marianne LaFrance calls\\n\"standing in social quicksand.\" So this really spikes your cortisol. So this is the job interview\\nwe put them through, because we really wanted\\nto see what happened. We then have these coders look\\nat these tapes, four of them. They\\'re blind to the hypothesis.\\nThey\\'re blind to the conditions. They have no idea\\nwho\\'s been posing in what pose, and they end up looking\\nat these sets of tapes, and they say,\\n\"We want to hire these people,\" all the high-power posers. \"We don\\'t want to hire these people. We also evaluate these people',\n",
              " 'question': 'who is Demis'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "Z2TBxQlYTgd6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain = parallel_chain | prompt | model | parser"
      ],
      "metadata": {
        "id": "bDM2xKC3TgcZ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_chain.invoke('what is the Conversation Going on in the video')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "beNo0064Tgab",
        "outputId": "479b9235-c8f4-4a1b-94b3-52714f31a55d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The conversation in the video appears to be a mix of Amy Cuddy's explanations about nonverbal behavior and body language, along with a discussion about a specific study she conducted on the effects of power posing on job interview outcomes.\\n\\nMore specifically, Amy Cuddy is explaining to the audience how her study found that individuals who adopted high-power poses before a job interview were perceived as more competent and likable by the interviewers, whereas those who adopted low-power poses were not.\\n\\nShe also discusses the importance of nonverbal communication and how it can affect our interactions with others. Additionally, she addresses a common misconception about her research, where people mistakenly assume that her study suggests adopting high-power poses before a job interview is a way to fake confidence. Instead, she emphasizes that the study is about the internal, psychological effect of power posing, rather than its external, social effects.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_from_youtube(url, question):\n",
        "    video_id = get_video_id(url)\n",
        "    if not video_id:\n",
        "        return \"Invalid YouTube URL.\"\n",
        "\n",
        "    yt = YouTubeTranscriptApi()\n",
        "\n",
        "    try:\n",
        "        # Fetch transcript and convert to dict format\n",
        "        transcript = [\n",
        "            {\"start\": e.start, \"duration\": e.duration, \"text\": e.text}\n",
        "            for e in yt.fetch(video_id, languages=['en'])\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching transcript: {e}\"\n",
        "\n",
        "    if not transcript:\n",
        "        return \"No transcript available for this video.\"\n",
        "\n",
        "    # Join text and split into chunks\n",
        "    full_text = \" \".join(entry[\"text\"] for entry in transcript)\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "    chunks = splitter.create_documents([full_text])\n",
        "\n",
        "    # Embed and create FAISS vector store\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "\n",
        "    # Retrieve relevant chunks\n",
        "    retrieved_docs = retriever.invoke(question)\n",
        "    context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "\n",
        "    # Create prompt and get answer\n",
        "    final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
        "    answer = model.invoke(final_prompt)\n",
        "\n",
        "    return answer.content\n",
        "\n",
        "# Build Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# YouTube Transcript QA Chatbot\")\n",
        "    url_input = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter YouTube video URL here\")\n",
        "    question_input = gr.Textbox(label=\"Question\", placeholder=\"Ask something about the video\")\n",
        "    output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "\n",
        "    btn = gr.Button(\"Get Answer\")\n",
        "    btn.click(fn=answer_from_youtube, inputs=[url_input, question_input], outputs=output)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "w-9OFDbfTgYc",
        "outputId": "0b99019d-5225-40e0-f7de-d25a81afb7a6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9c15af538b42528cec.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9c15af538b42528cec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Before optimization (e.g., no caching)\n",
        "start = time.time()\n",
        "\n",
        "# Run your slow function here (e.g., build vector store without cache)\n",
        "vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "end = time.time()\n",
        "original_latency = end - start\n",
        "print(f\"Original latency: {original_latency:.2f} seconds\")\n",
        "\n",
        "# After optimization (e.g., with caching)\n",
        "start = time.time()\n",
        "\n",
        "# Run your optimized function (e.g., get_vector_store which uses cache)\n",
        "vector_store = get_vector_store(\"Ks-_Mh1QhMc\", chunks, embeddings)\n",
        "\n",
        "end = time.time()\n",
        "optimized_latency = end - start\n",
        "print(f\"Optimized latency: {optimized_latency:.2f} seconds\")\n",
        "\n",
        "# Calculate % latency reduction\n",
        "latency_reduction = ((original_latency - optimized_latency) / original_latency) * 100\n",
        "print(f\"Latency reduced by: {latency_reduction:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjaYQhAETgWu",
        "outputId": "d138a983-2fd8-4200-b30a-588e676b04c3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original latency: 3.27 seconds\n",
            "Optimized latency: 0.00 seconds\n",
            "Latency reduced by: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WV41lJ1PTgVV"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "15ZbSumHTgTe"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2G53FouTgRr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZ2bIkVCTgPp"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1G_80kICTgOC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CVHiJJUTgK6"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8DsM99yTgGy"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3Y-wneDTgDn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fc0gBg9gTgAu"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0dQ9G4oTf94"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8SrsxWfTf6w"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0ASEE_zTf39"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}